% Chapter 4
\chapter{Meta Heuristic Extended Local Planning}\label{ch:meta}

In this chapter we propose an approach to extend local planning systems, which are based on trajectory simulation and evaluation. The main idea is to apply well established meta-heuristic search algorithms to find good trajectories given a sample of different applicable velocities, a robotic motion model and a given time period for simulation. 

We introduce trajectory selection extensions using a combination of meta-heuristic algorithms.

\begin{itemize}
\item{\bf{ILS-Tabu:}}  Based on Iterated Local Search and the use of a simple memory
\item{\bf{VNSB-Tabu:}} Based on Variable Neighborhood Search and the use of a simple memory and Best Improvement heuristic.
\item{\bf{VNSF-Tabu:}} Based on Variable Neighborhood Search and the use of a simple memory and First Improvement heuristic.
\end{itemize}

The proposed methods are tested and refined and implemented into a robotic navigation system which already supports implementations of a local planner based on Dynamic Window Approach and Trajectory Rollout.

\begin{itemize}
\item{\bf{VNSB-POSNEG}} Refining VNSB-Tabu with short term memory
\item{\bf{VNSF-POSNEG}} Refining VNSF-Tabu with short term memory
\end{itemize}

The next section provides background information of meta-heuristic search, followed by a detailed description about the specific algorithms used for extending local planners.

The relevant local planners we took into consideration are the aforementioned Dynamic Window Approach and Trajectory Roll-out planner, which will be discussed at the end of this chapter.

\section{Meta-Heuristic Search}
The family of meta-heuristic algorithms is extremely successful in solving optimization problems, and are heavily used to solve hard problems whether they are  \emph{discrete} (Combinatorial Problems: e.g. Traveling Salesman Problem (TSP), MAX-Sat problem, Nurse Rostering problems (NRP), Classical Vehicle Routing Problem (CVRP),...), or \emph{real-valued} (Continuous Optimization Problems: e.g. Pooling problem, Continues Min-Max problem,...).

In general an optimization problem and its solutions can be defined as follows (see \cite{blum2003metaheuristics}): 
\begin{definition}\label{def:problem}
An optimization problem $P = (S, f_c)$ can be defined by:\\
- a set of \emph{variables} $X = \{x_1,\dots,x_n\} $;\\
- a set of \emph{domains}, defining the values the variables can take $D_1,\dots,D_n$;\\
- possible \emph{constraints} on the variables\\
- a \emph{cost function} (or more general an \emph{objective function}) $f_c$ which has to be minimized, where $f_c:D_1 \times \dots \times D_n \rightarrow \mathbb{R}^+$; (which is the same as maximizing $-f_c$)\\
\end{definition}
The set of all possible assignments $S = \{s = \{(x_1,v_1),\dots,(x_n,v_n)\}\mid v_i \in D_i\}$ to the variables in $X$ is called the \emph{search} or \emph{solution space}.
A continues optimization problem is given if $S=\mathbb{R}^n$, otherwise if $S$ is discrete and finite a combinatorial optimization problem is given. 

Solutions which fulfill all constraints are called \emph{feasible} solutions, solutions violating constraints are called \emph{infeasible}. 
It is not necessary to allow only feasible solutions in the search space, as accepting infeasible solutions during the search process can improve the overall solution quality and performance of the algorithm.

The solution $s^*\in S$ of an optimization problem with minimum cost is called a \emph{global} optimal solution. 
\begin{definition}
 A \emph{global} minimal solution is a solution $s^* \in S$ such that
 $f_c(s^*)\leq f_c(s) \forall s \in S$. 
\end{definition}
Since there might be more than one optimal solution $S^* \subseteq S$ is the set of \emph{globally} optimal solutions.

To solve hard problems due to large solution space, hard run time constraints, or both, finding an exact global optimal solution is not always feasible. 
Instead a \emph{good} approximate solution, with the help of an heuristic is used and optimality is traded off with good performance.

One basic heuristic approximation method is local search which given an initial solution tries to iteratively replace this solution with a better one in a defined neighborhood of the current solution. 
\begin{definition}\label{def:neighborhood}
A neighborhood structure is a function $N:S\rightarrow 2^S$ that assigns to every $s \in S$ a set of neighbors $N(s) \subseteq S$. $N(s)$ is called the neighborhood of $s$.
\end{definition}
Defining the neighborhood function has an important influence on the good performance of many meta-heuristic algorithms. 
A neighborhood my be induced from metric functions introduced into $S$ given some notion of nearness within a given starting point. 
The necessary steps from one local solution to another local solution within a neighborhood is called a \emph{move}. Neighborhoods can also be induced by the set of applicable moves given a current solution (see \cite{gendreau2003tabusearch}).

Minimal solutions within a given neighborhood structure are defined as \emph{local} minimal solutions.
\begin{definition}
 A \emph{local} minimal solution w.r.t. a neighborhood structure $N$ is a solution $\hat{s}$  such that $\forall s_n \in N(\hat{s}):f_c(\hat{s})\leq f(s_n)$. 
\end{definition}
A visualization of the concepts of local vs. global minimal solutions is visualized in Figure~\ref{fig:fig_local_global}.
\begin{figure}[thpb]
   \footnotesize
   \centering
   \def\svgwidth{0.75\textwidth}
   \includesvg{figures/fig_local_global_minima}     
   \caption[]{This figures shows different kind of solutions to an optimization problem. The solutions $\hat{a}$ and $\hat{b}$ are local minimal solutions in the neighborhood $N_1(a)$ and $N_2(b)$ respectively, whereas the global minimal solution is $s^*$.}
   \label{fig:fig_local_global}
\end{figure}

The main idea of meta-heuristic algorithms is to combine heuristic methods with higher level strategic components to guide the search in an effective and economic manner. 
The name was introduced by Fred Glover who described his tabu search approach \grqq as a \emph{meta-heuristic} superimposed on another heuristic \grqq \cite{glover1988tabu}. 

How successful a meta-heuristic performs depends largely at how good it is to balance two important objectives during a search:
\begin{itemize}
\item{\bf{intensification:}} Focus the search on regions with high quality solutions, by using knowledge gained during the search process.
\item{\bf{diversification:}} Escaping local minimal solutions and visiting unexplored regions of the search space.
\end{itemize}

 
\section{Single Solution Based Meta-Heuristics}
As the name suggests these meta-heuristic approaches operate on improving a single solution during the search. 
Starting from an initial solution the search describes a single trajectory in the search space, when moving from one solution to another. 
Usually these methods incorporate local search as a component, and additional strategies to escape from local minimal solution.  

\subsection{Basic Local Search}
The basic local search (BLS) (cf. Algorithm~\ref{localsearchalgo}) finds a local optimum according to a cost function $f_c(x)$ in a region around an initial solution in the solution space, defined by a fixed neighborhood structure $N(x)$. 


\begin{algorithm}
\caption{Local Search  (BLS)}
\label{localsearchalgo}
\begin{algorithmic}[1] 
\State $x\gets$ initial solution
\Repeat
\State select a $x^\prime \in$ \Call{Neighborhood}{$x$}
\If {\Call{$cost$}{$x^\prime$} $\leq$ \Call{$cost$}{$x$}}
    \State $x\gets x^\prime$
\EndIf
\Until{no improvement}
\end{algorithmic}
\end{algorithm}

Starting from an initial solution it iteratively selects elements from the neighborhood which improve the current solution. The search stops at a local minimal solution if there are no improving solutions which can be selected.
Several possible selelction function can be applied. The most frequently from an exhaustive search of the neighborhood 



\subsection{Simulated Annealing}
One of the first algorithms considered a meta-heuristic is Simulated Annealing (SA), which was introduced in \cite{Kirkpatrick83SimulatedAnnealing}. 
Allowing to move to worse solutions during a local search with a certain probability, provides an explicit diversification mechanism to avoid getting trapped in local minimal solutions.
The interplay between intensification and diversification is controlled by the temperature  parameter $T$. 

\subsection{Iterative Local Search}
A nice survey of Iterative Local Search including the basic algorithm (cf. Algorithm~\ref{ilsalgo}) can be found in \cite{lourencco2001iterated}. 
The main idea is to call a local search procedure iteratively, until a certain stopping criteria is satisfied. 
In each iteration the current solution might be perturbed by changing parts of the solution. 
The following local search takes this altered solution as a starting point and returns a new solution. 
If it satisfies an acceptance condition (e.g. the best solution so far), the process restarts with the new solution. 
In addition, a history of already found solutions may be used to steer perturbation and the acceptance test.
The steps of ILS are visualized in Figure~\ref{fig:fig_ils}

\begin{figure}[thb] 
   \footnotesize
   \centering
    \def\svgwidth{0.75\textwidth}
    \includesvg{figures/fig_ils}
    \caption[Pertubation step in ILS]{Pertubation of a local minimal solution $\hat{s}$, leads to an intermediate solution $s^\prime$. A local search is applied and a new local minimal solution $\hat{s}^\prime$ is found. (reproduced from \cite{blum2003metaheuristics})}  
     \label{fig:fig_ils}
\end{figure}
 
\begin{algorithm}
\caption{Iterative Local Search (ILS)}
\label{ilsalgo}
\begin{algorithmic}[1]
\State $x_0\gets$ initial solution
\State $x^*\gets$ \Call{LocalSearch}{$x_0$}
\Repeat
\State $x^\prime \gets$ \Call{Perturbation}{$x^{*}$,history}
\State $x^{*\prime} \gets$ \Call{LocalSearch}{$x^\prime$}
\State $x^* \gets$ \Call{AcceptanceCriterion}{$x^{*}$,$x^{*\prime}$,history}
\Until{stopping criteria satisfied}
\end{algorithmic}
\end{algorithm}

\subsection{Variable Neighborhood Search}
Instead of using a fixed neighborhood, the Basic Variable Neighborhood Search (cf. Algorithm~\ref{vnsalgo}) as presented in \cite{VNS} uses a neighborhood structure of possibly nested neighborhoods (cf. Equation~\ref{eq:nb}), which together are guaranteed to explore the whole solution space. 
\begin{equation}
N_k(x)=N_0(x),N_1(x),\dots,N_{k_{max}}(x)
\label{eq:nb}
\end{equation}
A specific neighborhood structure determines the topology of the search space within this neighborhood, or in other words a neighborhood specific landscape (see \cite{blum2003metaheuristics}).

Different neighborhood structures yield different landscapes. 
Furthermore a local minimal solution within one landscape, does not have to be a local minimal solution in another, and a search procedure will find a better local minimal solution (see Figure~\ref{fig:fig_vns}). 

\begin{figure}[thb]
   \footnotesize
   \centering
   \myfloatalign
   \captionsetup[subfigure]{labelformat=empty} 
    \subfloat[]
    {  
       \def\svgwidth{0.5\textwidth}
       \includesvg{figures/fig_vns_1}
    }
    \subfloat[]
    {  
       \def\svgwidth{0.5\textwidth}
       \includesvg{figures/fig_vns_2}
    }
    \caption[Search landscapes of two different neighborhoods.]{This figures shows two different landscape from different neighborhood structures. On the left image the local search stops at the local minimal solution $\hat{s}_1$. On the right the local search can proceed to a better local minimum $\hat{s}_2$. (reproduced from \cite{blum2003metaheuristics})}  
     \label{fig:fig_vns}
\end{figure}

In the shaking phase the algorithm chooses a random solution of the current neighborhood to avoid getting captured in local minima. 
If the solution found by the Local Search does not improve the next neighborhood will be considered (cf. Algorithm~\ref{changealgo}).

\begin{algorithm}
\caption{Variable Neighborhood Search (VNS)}
\label{vnsalgo}
\begin{algorithmic}[1]
\Function{VNS}{$x,k_{max}$}
\Repeat
\State $k \gets 1$
\Repeat
\State $x^{\prime} \gets$ \Call{Shake}{$x,k$}
\State $x^{\prime \prime}\gets$ \Call{LocalSearch}{$x^{\prime}$}
\State \Call{NeighborhoodChange}{$x,x^{\prime \prime},k$}
\Until{$k=k_{max}$}
\Until{stopping criteria satisfied}
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Neighborhood Change}
\label{changealgo}
\begin{algorithmic}[1]
\Function{NeighborhoodChange}{$x,x^{\prime},k$}
\If {\Call{$cost$}{$x^\prime$} < \Call{$cost$}{$x$}}
    \State $x\gets x^\prime$
    \State $k\gets 1$
\Else
    \State $k\gets k+1$
\EndIf

\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection{Tabu Search}
Another successful Meta-Heuristic strategy is Tabu Search (cf. Algorithm~\ref{tabualgo}) proposed in \cite{glover1999tabu}. 
To avoid local minima a Tabu list keeps track of moves which are not allowed during the exploration of the current neighborhood. 
In its simplest form the Tabu list includes all visited solutions. 
This might be too restrictive, or the list might grow too large, hence one can restrict the list to a certain length, and delete e.g. the oldest item in the list in each iteration. 
One advantage of this method is, that it can be easily combined with other Meta-Heuristic algorithms.

\begin{algorithm}
\caption{Tabu Search}
\label{tabualgo}
\begin{algorithmic}[1]
\State $Tabulist \gets 0$
\State $x\gets$ initial solution
\Repeat
 \State $X^\prime \gets$ \Call{Neighborhood}{$x$} $\not\in Tabulist$
 \State $x^\prime \gets$ best solution in $X^\prime$
 \State $Tabulist = Tabulist \cup \{x^\prime\}$
 \State $x \gets x^\prime$
 \If{$x$ is overall best solution}
   \State store $x$ as best solution
 \EndIf
\Until{stopping criteria satisfied}
\end{algorithmic}
\end{algorithm}

\subsection{Guided Local Search}
Changing the neighborhood of solutions, as in the afforementioned algorithms like ILS and VNS, is not the only mechanism to escape local minimal solutions.
A very different approach in guiding the search for optimal solutions is Guided Local Search (GLS), and was introduced in (see \cite{TsangVoudouris1997gls}\cite{TsangVoudouris1999gls}). 

In this approach diversification is achieved by changing the cost function itself. 
The neighborhood structure stays fixed. 
For intensification a local search method is performed in each iteration.
In Figure~\ref{fig:fig_gls} the gradually change of the cost function which may lead to new local minimal solutions is visualized. 
\begin{figure}[thb] 
   \footnotesize
   \centering
    \def\svgwidth{0.75\textwidth}
    \includesvg{figures/fig_gls}
    \caption[Escaping a local minimal solution by gradually increasing the cost function.]{Escaping a local minimal solution by gradually increasing the cost function. (reproduced from \cite{blum2003metaheuristics})}  
     \label{fig:fig_gls}
\end{figure}

Altering the cost function is based on penalysing the presents of \emph{solution features} which are distinguishing properties of different solutions. The effect of the \emph{penalty parameters} on the cost function is in addition balanced via a \emph{regularization} parameter.  

\subsection{Greedy Randomized Adaptive Search Procedure (GRASP)}
\fxnote{Not sure if I include this too}

\section{Population Based Meta-Heuristics}
In contrast to the aforementioned methods, population based meta-heuristics operate on a set of solutions. Instead of a single trajectory, the search process describes \grqq the evolution of a set of points in the search space \grqq \cite{blum2003metaheuristics}.  
\subsection{Evolutionary Computation}
\subsection{Ant Colony Optimization}
\section{Classification and Comparison of Meta-Heuristics}

\section{Trajectory Selection Using Meta-Heuristics} \label{sec:trajselmeta}
The aforementioned trajectory selection for forward movements, evaluation and collision test are costly operations. 
The focus lies on improving this part of the DWA algorithm. 
The trajectory sampling and selection of the DWA are implemented in python minimizing a simpler cost function $f_c(v,w)$ (cf. Equation~\ref{eq:simplecost}), where $f_g(v,w)$ is the distance of the center of the robot in the end position to a predefined goal position, and $f_o(v,w)$ is the maximal distance to an obstacle on the trajectory path.

\begin{equation}
   f_c(v,w)=\alpha f_g(v,w) - \beta f_o(v,w)
   \label{eq:simplecost}
\end{equation}

Instead of performing an exhaustive \textit{Brute Force} search on all velocity samples, Meta-Heuristic algorithms are here used to boost the search performance. 

The reduced search space are all tuples of forward and angular velocities $(v,w)$ within given limits $v_{min} \leq v \leq v_{max}$ and $w_{min} \leq w \leq w_{max}$ and a step size for discretization by fixing the number of samples.

A generated costmap together with a visualization of consecutive local path planning steps in a simulation is shown in Figure~\ref{fig:fig_instances_detail}.
   
\begin{figure}[thpb]
     \footnotesize
      \centering
      \setlength\fboxsep{0pt}
      \setlength\fboxrule{0.5pt}
       \def\svgwidth{\textwidth}
       %\fbox{\includesvg{figures/fig_inst_25_new}}
       \includesvg{figures/fig_inst_25_new}
		\caption[Local-path planning simulation.]{This figure shows three applications of the local planner in a simulated experiment. The greyscale background image visualizes obstacle costs of a generated costmap. Trajectories in green are drive-able, whereas red trajectories collide with obstacles. In each local planning step possible trajectories are weighted with respect to obstacle closeness and progression towards goal destination. For example in the second step a longer valid trajectory is rejected, while a shorter trajectory which stays farther away from obstacles is selected for execution. After three local planning applications the robot safely reaches the goal destination.}
		\label{fig:fig_instances_detail}
\end{figure}

\subsection{Neighborhood}
The neighborhood of a solution is simply defined by making a number of discretization steps to reachable regions from the current solution velocity tuple. 
The 4-neighborhood makes a step by either increasing or decreasing the current linear and angular velocity by one discretization step (Manhattan distance $=1$). 
The 8-neighborhood takes all neighbors into account which are reachable in one discretization step (Moore neighborhood). 
16-neighborhood are all neighbors reachable in two steps. 
This process continues until the whole search space is the neighborhood. Figure~\ref{fig:fig_nb} visualizes the neighborhood structure.
\begin{figure}[thpb]
   \footnotesize
   \centering
   \def\svgwidth{\textwidth}
   \includesvg{figures/fig_neighborhood3d}     
   \caption[]{Neighborhood structure in the 2-dim velocity space.}
   \label{fig:fig_nb}
\end{figure}

\subsection{Local Search (LS)}
Using Local Search the neighborhood is either exhaustively searched for the best solution (Best-Improvement heuristic) or stopped after finding the first improving solution (First-Improvement heuristic).

\subsection{Tabu List}
Instead of recording all steps made in a Local Search run, all visited states are marked as tabu and will not be considered as valid solution in future steps of the algorithm. 
The Tabu list is used by the other Meta-Heuristic algorithm during the Local Search.

\subsection{Iterated Local Search (ILS)}
The perturbation step is very simplified and just finds the next random valid velocity tuple. 
Instead of altering the current solution in each step, we make use of the history and apply it after a fixed amount of iterations. 
The algorithm can use a 4,8, and 16-neighborhood with Best Improvement heuristic for the Local Search.

\subsection{Variable Neighborhood Search (VNS)}
For the VNS algorithm local search is performed in one neighborhood until no improvement occurs. 
The shaking chooses a random solution in the current neighborhood. 
If the shaking does not yield any solution, because the whole neighborhood is tabu, or does not include a collision free trajectory, the next neighborhood is chosen. 
An ordering of neighborhoods according to their size yields the neighborhood structure:
\begin{itemize}
 \item $N_0(x)=$ 4-connected
 \item $N_1(x)=$ 8-neighborhood
 \item $\dots$
 \item $N_k(x)=$ k-steps reachable neighborhood.
\end{itemize}
Larger neighborhoods are too costly to evaluate. 
Therefore the neighborhood structure is bounded above by $k_{max}=8$. 
If no improvement is made up to the $N_{k_{max}}$ neighborhood, a new initial solution is generated at random. 
The VNS algorithm can be used with Best-, or First-Improvement heuristic for the Local Search.

