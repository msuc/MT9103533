% Chapter 4
\chapter{Meta Heuristic Local Planning}\label{ch:meta}

This thesis proposes an approach to enhance certain types of local planning systems.
Examples of such local planners are the aforementioned Dynamic Window Approach and Trajectory Roll-out planner, which were introduced in Section~\ref{sec:dwa}.

The idea is to apply well established meta-heuristic search algorithms to find good trajectories given a sample of different applicable velocities, a robotic motion model and a given time period for simulation.
This work introduces trajectory selection extensions using a combination of meta-heuristic algorithms.

\begin{itemize}
\item{\bf{ILS-Tabu:}}  Based on Iterated Local Search and the use of a simple memory
\item{\bf{VNSB-Tabu:}} Based on Variable Neighborhood Search and the use of a simple memory and Best Improvement heuristic.
\item{\bf{VNSF-Tabu:}} Based on Variable Neighborhood Search and the use of a simple memory and First Improvement heuristic.
\end{itemize}

The proposed methods are tested and refined and implemented into a robotic navigation system which already supports implementations of a local planner based on Dynamic Window Approach and Trajectory Roll-out.

\begin{itemize}
\item{\bf{VNS-ROL:}} Refined VNSB-Tabu with short term memory for Rollout planner
\item{\bf{VNS-DWA:}} Refined VNSB-Tabu with short term memory for DWA planner
\end{itemize}

The next section provides background information of meta-heuristic search. 
Following well known classifications of meta-heuristics (see \cite{blum2003metaheuristics}, \cite{birattari2001classification} ) an introduction of \emph{single solution based} meta heuristics is given, which are the main source for the proposed approach. 

This chapter is then concluded by a detailed description about how meta-heuristics are used to extend local planners in the trajectory selection process. 
Furthermore all relevant information concerning the local planners is provided. 

\section{Meta-Heuristic Search}\label{sec:meta}
The family of meta-heuristic algorithms is known to be successful in solving optimization problems, and are heavily used to solve hard problems whether they are  \emph{discrete} (Combinatorial Problems: e.g. Traveling Salesman Problem (TSP), MAX-Sat problem, Nurse Rostering problems (NRP), Classical Vehicle Routing Problem (CVRP),...), or \emph{real-valued} (Continuous Optimization Problems: e.g. Pooling problem, Continues Min-Max problem,...).

In general an optimization problem and its solutions can be defined as follows  \cite{blum2003metaheuristics}: 
\begin{definition}\label{def:problem}
An optimization problem $P = (S, f_c)$ can be defined by:\\
- a set of \emph{variables} $X = \{x_1,\dots,x_n\} $;\\
- a set of \emph{domains}, defining the values the variables can take $D_1,\dots,D_n$;\\
- possible \emph{constraints} on the variables\\
- a \emph{cost function} (or more general an \emph{objective function}) $f_c$ which has to be minimized, where $f_c:D_1 \times \dots \times D_n \rightarrow \mathbb{R}^+$; (which is the same as maximizing $-f_c$)\\
\end{definition}
The set of all possible assignments $S = \{s = \{(x_1,v_1),\dots,(x_n,v_n)\}\mid v_i \in D_i\}$ to the variables in $X$ is called the \emph{search} or \emph{solution space}.
A continues optimization problem is given if $S=\mathbb{R}^n$, otherwise if $S$ is finite but large set a combinatorial optimization problem is given \cite{VNS}. 

Solutions which fulfill all constraints are called \emph{feasible} solutions, solutions violating constraints are called \emph{infeasible}. 
It is not necessary to allow only feasible solutions in the search space, as accepting infeasible solutions during the search process can improve the overall solution quality and performance of the algorithm.

The solution $s^*\in S$ of an optimization problem with minimum cost is called a \emph{global} optimal solution. 
\begin{definition}
 A \emph{global} minimal solution is a solution $s^* \in S$ such that
 $f_c(s^*)\leq f_c(s) \forall s \in S$ \cite{blum2003metaheuristics}. 
\end{definition}
Since there might be more than one optimal solution $S^* \subseteq S$ is the set of \emph{globally} optimal solutions.

Due to large solution space, or hard run time constraints finding an exact global optimal solution is not always feasible. 
Instead a \emph{good} approximate solution, with the help of an heuristic is used and optimality is traded off with good performance.

One basic heuristic approximation method is local search. 
Given an initial solution local search tries to iteratively replace this solution with a better one in a defined neighborhood of the current solution. 
\begin{definition}\label{def:neighborhood}
A neighborhood structure is a function $N:S\rightarrow 2^S$ that assigns to every $s \in S$ a set of neighbors $N(s) \subseteq S$. $N(s)$ is called the neighborhood of $s$ \cite{blum2003metaheuristics}.
\end{definition}
Defining the neighborhood function has an important influence on the good performance of many meta-heuristic algorithms. 
A neighborhood may be induced from metric functions introduced into $S$ given some notion of nearness within a given starting point. 

The steps from one local solution to another local solution within a neighborhood is called a \emph{move}. Neighborhoods can also be induced by the set of applicable moves given a current solution \cite{gendreau2003tabusearch}.

Minimal solutions within a given neighborhood structure are defined as \emph{local} minimal solutions.
\begin{definition}
 A \emph{local} minimal solution w.r.t. a neighborhood structure $N$ is a solution $\hat{s}$  such that $\forall s_n \in N(\hat{s}):f_c(\hat{s})\leq f(s_n)$ \cite{blum2003metaheuristics}. 
\end{definition}
A visualization of the concepts of local vs. global minimal solutions is visualized in Figure~\ref{fig:fig_local_global}.
\begin{figure}[thpb]
   \footnotesize
   \centering
   \def\svgwidth{0.75\textwidth}
   \includesvg{figures/fig_local_global_minima}     
   \caption[]{This figures shows different kind of solutions to an optimization problem. The solutions $\hat{a}$ and $\hat{b}$ are local minimal solutions in the neighborhood $N_1(a)$ and $N_2(b)$ respectively, whereas the global minimal solution is $s^*$.}
   \label{fig:fig_local_global}
\end{figure}

The main idea of meta-heuristic algorithms is to combine heuristic methods with higher level strategic components to guide the search in an effective and economic manner. 
The name was introduced by Fred Glover who described his tabu search approach \grqq as a \emph{meta-heuristic} superimposed on another heuristic \grqq \cite{glover1988tabu}. 

How successful a meta-heuristic performs depends largely at how good it is to balance two important objectives during a search:
\begin{description}
\item[Intensification]\hfill \\
The search focuses on regions with high quality solutions, which are identified using knowledge gained during the search process.
\item[Diversification]\hfill \\
The search escapes a local minimal solution and visits unexplored regions of the search space.
\end{description}

 
\section{Single Solution Based Meta-Heuristics}\label{sec:single}
As the name suggests these meta-heuristic approaches operate on improving a single solution during the search. 
Starting from an initial solution the search describes a single trajectory in the search space, when moving from one solution to another. 
Usually these methods incorporate local search as a component, and additional strategies to escape from local minimal solution.  

\subsection{Local Search}\label{sec:ls}
The simple local search (LS) (cf. Algorithm~\ref{localsearchalgo}) finds a local optimum according to a cost function $f_c(x)$ in a region around an initial solution in the solution space, defined by a neighborhood structure $N(x)$. 

\begin{algorithm}
\caption{Local Search  (LS)}
\label{localsearchalgo}
\begin{algorithmic}[1] 
\State $x\gets$ initial solution
\Repeat
\State $x\gets$ \Call{Select}{$x$}
\Until{no improvement}
\end{algorithmic}
\end{algorithm}

Starting from an initial solution it iteratively selects elements from the neighborhood which improve the current solution. 
The search stops at a local minimal solution if there are no improving solutions which can be selected.

The most frequently used selection functions are \emph{Best Improvement}(or steepest descent) (cf. Algorithm~\ref{bestimprov}), which exhaustively looks at each neighbor to select the best solution, and \emph{First Improvement} (or first descent) (cf. Algorithm~\ref{firstimprov}), which looks at the neighbors in a specific order and returns as soon as a better neighbor is found. 

\begin{algorithm}
\caption{Best Improvement}
\label{bestimprov}
\begin{algorithmic}[1] 
\Function{BestImprovement}{$x$}
\State $i \gets 0$
\Repeat
\State $i \gets i+1$
\State $x_i \in N(x)$, retrieve the i-th neighbor
\If {\Call{$cost$}{$x_i$} $<$ \Call{$cost$}{$x$}}
    \State $x \gets x_i$
\EndIf
\Until{$i=|N(x)|$}
\State \Return $x$
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{First Improvement}
\label{firstimprov}
\begin{algorithmic}[1] 
\Function{FirstImprovement}{$x$}
\State $i \gets 0$
\Repeat
\State $i \gets i+1$
\State $x_i \in N(x)$, retrieve the i-th neighbor
\Until{$i=|N(x)|$ or \Call{$cost$}{$x_i$} $<$ \Call{$cost$}{$x$}}
\State \Return \Call{$argmin$}{\Call{$cost$}{$x_i$} , \Call{$cost$}{$x$}}
\EndFunction
\end{algorithmic}
\end{algorithm}

Another possibility is to choose a neighbor at random, or choose the best neighbor among a random sample taken from the current neighborhood. These strategies could be used if the number of neighbors is very large, or their evaluation is computational expensive.

\subsection{Tabu Search} \label{sec:tabu}
An often successful meta-heuristic strategy is Tabu Search \cite{glover1988tabu}, which uses memory structures called \emph{tabu lists} to guide the search process.

The memory keeps track of complete solutions (\emph{explicit} memory), moves, partial solutions, or other solution attributes (\emph{attributive} memory), which are used to prohibit moves during the exploration of the search space for a given amount of time - they are \emph{tabu}\footnote{The word tabu (or taboo) stems from an Polynesian language and indicates things which may not be touched \cite{glover1997tabu}}. In Algorithm~\ref{tabualgo} the basic form of this approach is presented. 

\begin{algorithm}
\caption{Tabu Search}
\label{tabualgo}
\begin{algorithmic}[1]
\State $Tabulist \gets 0$
\State $x\gets$ initial solution
\Repeat
 \State $X^\prime \gets$ \Call{Neighborhood}{$x$} $\not\in Tabulist$
 \State $x^\prime \gets$ best solution in $X^\prime$
 \State $Tabulist = Tabulist \cup \{x^\prime\}$
 \State $x \gets x^\prime$
 \If{$x$ is overall best solution}
   \State store $x$ as best solution
 \EndIf
\Until{stopping criteria satisfied}
\end{algorithmic}
\end{algorithm}

The main usage of tabu lists is to prevent cycling back to recent solutions, and prevents from searching the same region of the search space over and over again. 
This \emph{short term memory} approach contributes to the \emph{diversification} of the search, since the neighborhood of solutions is changed dynamically according to their tabu status. 

Usable other types of memory structures are the following (presented in ~\cite{glover1997tabu}):  
\begin{description}
\item[Recency-based memory]\hfill \\
Recording when an attribute or solution was used in the search process.
\item[Frequency-based memory]\hfill \\
Recording how often an attribute or solution was used during the search process. 
\item[Quality-based memory]\hfill \\
Recording attributes or solutions which lead to, or are common to good solutions.
\item[Influence-based memory]\hfill \\
Recording information of attributes or solution considering the impact of solution quality and structure.
\end{description}

According to the \emph{short term memory} analogy of the human memory, tabu lists can be furthermore classified in \emph{intermediate term memory}, and \emph{long term memory} strategies \cite{gendreau2003tabusearch}.
\begin{description}
\item[short term memory]\hfill \\
Used for \emph{diversification} of the search. Keep track of a small amount of recent moves, thus avoid cycling back to recent solutions. 
\item[intermediate term memory]\hfill \\
Used for \emph{intensification} of the search. For example use a recency-based memory, which records good solution and restart the search from these elite solutions.
\item[long term memory]\hfill \\
Used for \emph{diversification} of the search. For example implementing a frequency-based memory recording the total number of iterations in which solutions or their components have been used in the current solution. Restart the search using solutions which have a lower number of iterations.
\end{description}

An important role in controlling the \emph{diversification} of the search is the length of tabu lists (\emph{tabu tenure}).  
As a general rule the longer the tabu list the higher the diversification effect, since preventing a larger number of candidate solutions in a neighborhood drastically changes the solution landscape \cite{blum2003metaheuristics}. 

Restricting the tabu lists length is usually achieved by implementing it as cyclic lists, and deleting e.g. the oldest item as soon as a new item becomes tabu. 
The tabu tenure can both be fixed or may be changed during the search.

To avoid the tabu lists being too restrictive, and possibly loose good solutions, the tabu status of solutions may also be overridden using an \emph{aspiration criteria}. One example of such an criteria is to always allow solutions which are overall best, even if they are tagged as tabu.

A big advantage of this method is, that it can be easily combined with other meta-heuristic algorithms.

\subsection{Iterated Local Search}\label{sec:ils}
Iterated Local Search provides a highly general scheme for search space exploration. 
It emphasizes the idea of treating the local search procedure as a black box, which in the ideal case incorporates all problem specific knowledge. 
A detailed description of Iterative Local Search including the basic algorithm (cf. Algorithm~\ref{ilsalgo}) can be found in \cite{lourencco2001iterated}.

Starting from an initial solution, the algorithm iteratively calls the embedded \emph{local search} procedure.
In each iteration the current solution might be \emph{perturbed} by changing parts of the solution. 
The following \emph{local search} takes this altered solution as a new starting point and if it satisfies an \emph{acceptance criterion} the search restarts with \emph{perturbating} this new solution. 

The basic steps of ILS are visualized in Figure~\ref{fig:fig_ils}

\begin{figure}[thb] 
   \footnotesize
   \centering
    \def\svgwidth{0.75\textwidth}
    \includesvg{figures/fig_ils}
    \caption[Perturbation step in ILS]{Perturbation of a local minimal solution $\hat{s}$, leads to an intermediate solution $s^\prime$. A local search is applied and a new local minimal solution $\hat{s}^\prime$ is found. (reproduced from \cite{blum2003metaheuristics})}  
     \label{fig:fig_ils}
\end{figure}

The \emph{strength} of the perturbation is defined as the number of changed solution components. 
If the perturbation strength is large, the \emph{diversification} effect is large and the procedure is similar to a random restart method. On the other hand if the strength is small, perturbation favors the \emph{intensification} of the search. The strength may be fixed but may also be adapted during the search \cite{lourencco2001iterated}.

The \emph{acceptance criterion} is the other mechanism in ILS which controls the interplay between \emph{diversification} and \emph{intensification} of the search. 
On one extreme accepting only better solution favors intensification, on the other extreme accepting all solutions without regards to its costs has a high diversification effect. Every intermediate mechanism and incorporating adaptive strategies may be used in designing acceptance tests.  

Another important component is the use of short or long term memory concepts, which may be included in form of a \emph{history} of the search. The \emph{history} is used to steer the perturbation step and the acceptance test (compare to Tabu Search memory structures in Section~\ref{sec:tabu}). As a simple example the history counts the iterations and restarts the algorithm after reaching a specific amount of iteration.
 
\begin{algorithm}
\caption{Iterative Local Search (ILS)}
\label{ilsalgo}
\begin{algorithmic}[1]
\State $x_0\gets$ initial solution
\State $x^*\gets$ \Call{LocalSearch}{$x_0$}
\Repeat
\State $x^\prime \gets$ \Call{Perturbation}{$x^{*}$,history}
\State $x^{*\prime} \gets$ \Call{LocalSearch}{$x^\prime$}
\State $x^* \gets$ \Call{AcceptanceCriterion}{$x^{*}$,$x^{*\prime}$,history}
\Until{stopping criteria satisfied}
\end{algorithmic}
\end{algorithm}

\subsection{Variable Neighborhood Search}\label{sec:vns}
Instead of using a fixed neighborhood, the Basic Variable Neighborhood Search (cf. Algorithm~\ref{vnsalgo}) as presented in \cite{VNS} uses a neighborhood structure of possibly nested neighborhoods (cf. Equation~\ref{eq:nb}), which together are guaranteed to explore the whole solution space. 
\begin{equation}
N_k(x)=N_0(x),N_1(x),\dots,N_{k_{max}}(x)
\label{eq:nb}
\end{equation}
A specific neighborhood structure determines the topology of the search space within this neighborhood, or in other words a neighborhood specific landscape \cite{blum2003metaheuristics}.

Different neighborhood structures yield different landscapes. 
Furthermore a local minimal solution within one landscape, does not have to be a local minimal solution in another, and a search procedure will find a better local minimal solution (see Figure~\ref{fig:fig_vns}). 

\begin{figure}[thb]
   \footnotesize
   \centering
   \myfloatalign
   \captionsetup[subfigure]{labelformat=empty} 
    \subfloat[]
    {  
       \def\svgwidth{0.5\textwidth}
       \includesvg{figures/fig_vns_1}
    }
    \subfloat[]
    {  
       \def\svgwidth{0.5\textwidth}
       \includesvg{figures/fig_vns_2}
    }
    \caption[Search landscapes of two different neighborhoods.]{This figures shows two different landscape from different neighborhood structures. On the left image the local search stops at the local minimal solution $\hat{s}_1$. On the right the local search can proceed to a better local minimum $\hat{s}_2$. (reproduced from \cite{blum2003metaheuristics})}  
     \label{fig:fig_vns}
\end{figure}

In the \emph{shaking} phase the algorithm chooses a random solution of the current neighborhood to avoid getting captured in a local minima.  

If the solution found by local search does not improve the next neighborhood will be considered (cf. Algorithm~\ref{changealgo}). 
The selection of this neighborhood might be deterministic, but also other schemes are possible. For example one could randomly choose the next neighborhood, or use additional parameter to adjust the step sizes for the \emph{neighborhood change} dynamically.

Variants of this basic scheme are obtained by removing the random shaking phase, which results in deterministic descent method called \emph{Variable neighborhood descent} (VND). Omitting the local search step results in the \emph{Reduced VNS} (RVNS) method, which is a purely stochastic method.

\begin{algorithm}
\caption{Variable Neighborhood Search (VNS)}
\label{vnsalgo}
\begin{algorithmic}[1]
\Function{VNS}{$x,k_{max}$}
\Repeat
\State $k \gets 1$
\Repeat
\State $x^{\prime} \gets$ \Call{Shake}{$x,k$}
\State $x^{\prime \prime}\gets$ \Call{LocalSearch}{$x^{\prime}$}
\State \Call{NeighborhoodChange}{$x,x^{\prime \prime},k$}
\Until{$k=k_{max}$}
\Until{stopping criteria satisfied}
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Neighborhood Change}
\label{changealgo}
\begin{algorithmic}[1]
\Function{NeighborhoodChange}{$x,x^{\prime},k$}
\If {\Call{$cost$}{$x^\prime$} < \Call{$cost$}{$x$}}
    \State $x\gets x^\prime$
    \State $k\gets 1$
\Else
    \State $k\gets k+1$
\EndIf

\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection{Guided Local Search}
Changing the neighborhood of solutions, as in the aforementioned algorithms like ILS and VNS, is not the only mechanism to escape local minimal solutions.
A very different approach in guiding the search for optimal solutions is Guided Local Search (GLS), and was introduced by Tsang and Voudouris \cite{TsangVoudouris1997gls}\cite{TsangVoudouris1999gls}. 

In this approach diversification is achieved by changing the cost function itself. 
The neighborhood structure stays fixed. 
For intensification a local search method is performed in each iteration.
In Figure~\ref{fig:fig_gls} the gradually change of the cost function which may lead to new local minimal solutions is visualized. 
\begin{figure}[thb] 
   \footnotesize
   \centering
    \def\svgwidth{0.75\textwidth}
    \includesvg{figures/fig_gls}
    \caption[Escaping a local minimal solution by gradually increasing the cost function.]{Escaping a local minimal solution by gradually increasing the cost function. (reproduced from \cite{blum2003metaheuristics})}  
     \label{fig:fig_gls}
\end{figure}

Altering the cost function is based on penalizing the presence of \emph{solution features} which are distinguishing properties of different solutions. 
The effect of the \emph{penalty parameters} on the cost function is in addition balanced via a \emph{regularization} parameter.  

\subsection{Simulated Annealing}
Simulated Annealing (SA), which is one of the first algorithms considered a meta-heuristic, concludes this presentation of single solution based meta-heuristics. 

It was introduced in \cite{Kirkpatrick83SimulatedAnnealing}, and provides an explicit \emph{diversification} mechanism to avoid getting trapped in local minimal solutions. 
This is achieved by allowing moves to worse solutions during a local search with a certain probability (metropolis criterion, see~\ref{eq:metropolis}).
\begin{equation}
   P(accept(x^\prime))=\exp{(\frac{-|f_c(x^\prime)-f_c(x)|}{T})}
   \label{eq:metropolis}
\end{equation} 
The interplay between \emph{intensification} and \emph{diversification} is controlled by the temperature  parameter $T$. A high temperature yields a high probability for moving to the new solution. On the other hand a low temperature makes it less probable to leave the current neighborhood.

Decreasing the temperature during the search is called \emph{annealing}, referring to the intuition of physical annealing processes, which sets materials in a stable (optimal) state by reducing their temperature. 

Beside this basic form of a \emph{cooling schedule} oscillating schemes can be implemented (\emph{reheating}) which cycle between \emph{intensifiction} and \emph{diversification} phases. 

\section{Summary}
The presented meta-heuristics provide a powerful tool for general purpose optimization. 
This work restricts the collection of investigated algorithms which operate on a single solution.
In contrast to the aforementioned methods, population based meta-heuristics operate on a set of solutions. Instead of a single trajectory, the search process describes \grqq the evolution of a set of points in the search space \grqq \cite{blum2003metaheuristics}.  
Examples of such algorithms include methods based on Evolutionary Computation, Ant Colony Optimization, and Artificial Immune Systems.
For an in depth presentation of current meta-heuristic methods see \cite{Gendreau2010}.

The next section covers the approach to apply meta-heuristic search in the context of local planning.

\clearpage
\section{Trajectory Selection Using Meta-Heuristics} \label{sec:trajselmeta}
One basic step in creating a good local planner for mobile robots is the aforementioned trajectory selection. Especially forward movements are of particular interest, since their evaluation and collision tests are costly operations.
Only if forward movement does not yield valid movements, other strategies have to be applied, which provide escaping mechanisms, like turning around for relocation, or slow random backward movements to help the robot evade situations where it gets stuck. 
The use of escaping mechanisms should be limited, since they are only relevant if the usual planning step fails. 

In this thesis the focus lies on improving the trajectory selection of local planners using meta-heuristic algorithm. 

Instead of following an exhaustive generate and test procedure on all velocity samples, meta-heuristic algorithms are used to increase the search performance. 

Increasing the performance of the local planner has an important impact on the resulting path and behavior of the robot. 
It allows for increasing the following properties of local planner:
\begin{description}
\item[Reactivity]\hfill \\
Clearly one benefit of decreasing the time the local planning steps take is its increased reactivity. The faster and hence more often the local planner can be invoked to adapt to recent sensory information.

\item[Resolution]\hfill \\
The performance gain can be used to increase the resolution of cost-maps and collision test of the robot.

\item[Simulation-time]\hfill \\
Performing longer simulation periods results often in smoother paths since the robot can react early to possible obstructions. In addition it might also find shortcuts at an earlier stage, which results in a shorter path. 

\item[Trajectory-number]\hfill \\
Another very important quality benefit is the number of trajectory samples the local planner can use for making a decision. A higher number of trajectories increases the granularity of the cost function it optimizes. In the end this yields a smoother and more effective path (see Figure~\ref{fig:fig_smooth}).

\begin{figure}[thb]
   \footnotesize
   \centering
   \setlength\fboxsep{0pt}
   \setlength\fboxrule{0.5pt}
   \myfloatalign
   \captionsetup[subfigure]{labelformat=empty} 
    \subfloat[]
    {  
       \def\svgwidth{\textwidth}
       \includesvg{figures/fig_curvature}
    }
    \caption[Comparison of two paths generated using different amounts of trajectories.]{Comparison of two paths generated using different amounts of trajectories. The dotted path was generated with 150, and the other one with 3500 trajectories. The higher amount of sampled trajectories results in a smoother and more effective path.}  
     \label{fig:fig_smooth}
\end{figure}
\end{description}

The choice of using single solution based meta-heuristics (see Section~\ref{sec:single}) was driven by the properties these algorithms provide. 
They are \emph{general applicable} to optimization problems, since no domain specific knowledge is necessary, or can easily be captured using only the local search procedure.
Furthermore they are easy to implement and incorporated into existing software solutions.
Looking at the high number of parameters used for configuring current navigation systems the \emph{configuration process} is very tedious. 
Hence introducing lots of new parameters does not make it easier to find suitable configurations.
Meta-heuristics are well suited for this task because they use only few parameters to achieve good performance.  

In order to use meta-heuristics the local planning problem has to be formulated according to the definitions given in Section~\ref{sec:meta}.

Since this work deals with the navigation of non-holonomic robots moving on a 2D-plane workspace, the \emph{input variables} are all tuples of forward and angular velocities $(v,w)$ the robot is capable.
The \emph{domain} of the variables is a discrete set of the real valued search space induced by using a fixed stepping size and selecting a specific amount of trajectories.
 
Forward and angular velocities $(v,w)$ are furthermore \emph{constrained} within given limits $v_{min} \leq v \leq v_{max}$ and $w_{min} \leq w \leq w_{max}$.

The optimization problem is given as a function over the control inputs (velocity tuples) for the motor controller. 
The costs are calculated using a simulation of the robot with the given input velocity tuple and projecting the outline of the robot onto a cost-map. 

A generated cost-map together with a visualization of consecutive local path planning steps in a simulation is shown in Figure~\ref{fig:fig_instances_detail}.
   
\begin{figure}[thpb]
     \footnotesize
      \centering
      \setlength\fboxsep{0pt}
      \setlength\fboxrule{0.5pt}
       \def\svgwidth{\textwidth}
       %\fbox{\includesvg{figures/fig_inst_25_new}}
       \includesvg{figures/fig_inst_25_new}
		\caption[Local-path planning simulation.]{This figure shows three applications of the local planning step in a simulated experiment. The greyscale background image visualizes obstacle costs of a generated cost-map. The green trajectories are drive-able, whereas red trajectories collide with obstacles. At each local planning step all possible trajectories are weighted with respect to their distance to obstacles and their progression towards the goal destination. For example in the second step a valid trajectory which comes closer to the goal is rejected, while a shorter trajectory which stays farther away from obstacles is selected for execution. After performing three local planning applications the robot safely reaches the goal destination.(taken from \cite{myself})}
		\label{fig:fig_instances_detail}
\end{figure}

Solutions which do not exceed a given cost threshold are \emph{feasible} and free of collision. 
On the other hand solutions which reach a given maximum cost value indicating a collision with an object are considered \emph{infeasible}.

The \emph{neighborhood} of a solution is simply defined by making a number of discretization steps to reachable regions from the current solution velocity tuple. 
The 4-neighborhood makes a step by either increasing or decreasing the current linear and angular velocity by one discretization step (Manhattan distance $=1$). 
The 8-neighborhood takes in addition also the diagonal neighbors into account which are reachable in one discretization step (Moore neighborhood). 
16-neighborhood are all neighbors reachable in two steps. 
This process continues until the whole search space is the neighborhood. Figure~\ref{fig:fig_nb} visualizes the neighborhood structure.
\begin{figure}[thpb]
   \footnotesize
   \centering
   \def\svgwidth{\textwidth}
   \includesvg{figures/fig_neighborhood3d}     
   \caption[]{Neighborhood structure in the 2-dim velocity space.}
   \label{fig:fig_nb}
\end{figure}

Using \emph{Local Search} (see Section~\ref{sec:ls}) the neighborhood is either exhaustively searched for the best solution using Best-Improvement heuristic or stopped after finding the first improving solution using First-Improvement heuristic.

The following list includes the meta-heuristic algorithms used for the proposed approach.

\begin{description}
\item[Tabu List]\hfill \\
The \emph{memory structures} (see Section~\ref{tabualgo}) used in the proposed algorithms are very simple. 
Since the run-time requirements are very demanding, long term strategies are less suited to provide good results.

The first strategy keeps all visited states during the search as tabu. They will not be considered as valid solution in future steps of the search process. 

A slightly more sophisticated strategy is used in the extension of existing planner.
Here two types of tabu lists are present.
\begin{enumerate}
\item{long term memory:} Keeps all \emph{infeasible} velocity tuples which lead to collision. The are never considered again in future searches. This is possible since the solution space is not too large.
\item{short term memory:} Classical tabu list, with parametrized \emph{tabu tenure} which keeps the most recently visited \emph{feasible} velocity tuples.
\end{enumerate}

The idea of avoiding the neighborhood of infeasible solutions and allowing to return to \emph{good} feasible solutions during search was inspired by the grid like representation of the search space, which resembles the famous guessing game Battleship. 

The goal of the game is to try to hit all of the opponent ships, which can be viewed as the dual problem to obstacle avoidance. 
If a player hits a ship during the game, a good strategy is to try out the immediate neighbors until the ship is destroyed. 
In obstacle avoidance the opposite may be more efficient. If an obstacle is encountered, avoid its immediate neighbors.

The tabu list is used by the other meta-heuristic algorithms during the Local Search.
\item[Iterated Local Search (ILS)]\hfill \\
The main structure of this algorithm was already shown in Section~\ref{ilsalgo}.
The algorithm searches iteratively a fixed neighborhood (eg. 4-, or 8-connected neighborhood) with Best Improvement heuristic for the Local Search.

Since the solution vector is only 2-dimensional, there is no need for complicated perturbation schemes. 
It is possible to either randomly generate a new linear velocity, a new angular velocity or both. 

Using the \emph{history} capability of ILS it is possible to apply the perturbation step after a fixed amount of iterations. 
Furthermore one can parametrize the algorithm to restart if the neighborhood is empty due to invalid neighbors or the application of the tabu list. 


\item[Variable Neighborhood Search (VNS)]\hfill \\
For the VNS algorithm local search is performed in one neighborhood until no improvement occurs.
The used algorithm follows the scheme shown in Section~\ref{fig:fig_vns}.

The algorithm starts with either a random initial solution, or with the best solution found in the previous local planning step. 
In the \emph{shaking} phase a new random solution in the current neighborhood is selected. 
If \emph{shaking} does not yield a solution, because the whole neighborhood is tabu, or does not include a collision free trajectory, the next neighborhood is chosen. 

An ordering of neighborhoods according to their size yields the neighborhood structures:
\begin{itemize}
 \item $N_0(x)=$ 4-connected
 \item $N_1(x)=$ 8-connected
 \item $\dots$
 \item $N_k(x)=$ k-steps reachable neighborhood.
\end{itemize}
The different neighborhoods are nested which yield the following structure of neighborhoods:

$N_0 \subseteq N_1 \subseteq \dots \subseteq N_k$

In theory the union of all neighborhood is larger or equal the whole solution space of velocity tuples.
Unfortunately large neighborhoods are very costly to evaluate. 
Therefore the neighborhood structure can be bounded above by a parameter $k_{max}$.
If no improvement is made up to the $N_{k_{max}}$ neighborhood, a new initial solution is generated at random and the search starts up again.

Like the aforementioned ILS algorithm the VNS algorithm can use the same \emph{memory structures} during the search.

The VNS algorithm can be used with Best-, or First-Improvement heuristic for the Local Search.
\end{description}




